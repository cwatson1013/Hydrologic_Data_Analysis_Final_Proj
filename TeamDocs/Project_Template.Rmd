---
output: 
  pdf_document:
    keep_tex: yes
    fig_caption: yes
    number_sections: yes
geometry: margin=2.54cm
title: Examining the Hydrologic Properties of the Missouri River Basin
subtitle: https://github.com/cwatson1013/Hydrologic_Data_Analysis_Final_Proj
author: Rachel Bash, Keqi He, Caroline Watson, and Haoyu Zhang
abstract: "The Missouri River provides critical water resources that drives the region's agriculture, industry, and ecosystems. This is a region that experiences surface water variability, characterized by damaging floods and severe droughts, greatly impacting the agricultural production of the area. It is reported that a serious flood disaster occurred in the lower Missouri River in the spring of 2019 and the Missouri River experienced severe drought in 2012-2013. This project highlights the changes in stream flow and water quality over time, and identifies key characteristics of the river. Twenty two sites across the lower Missouri River Basin were examined in order to get a fuller picture of the Missouri River and its tributaries over time. By analyzing the trend of the Missouri River discharge, we can predict future changes in the Missouri River flow to provide a reference for water resources management. In addition, we focus on the stream flow and water quality of Missouri River during March to July, 2019 to see how discharge influence the water quality and what can be done to keep the water in the Missouri River in good quality."
fontsize: 12pt
mainfont: Times New Roman
editor_options: 
  chunk_output_type: console
---

<Information in these brackets are used for annotating the RMarkdown file. They will not appear in the final version of the PDF document>

\newpage
\tableofcontents 
\newpage
\listoftables 
\newpage
\listoffigures 
\newpage

<Setup the global options for the R chunks in your document>

<Note: set up autoreferencing for figures and tables in your document>

```{r setup, include=FALSE, warning=FALSE, message=FALSE}
# Set your working directory

getwd()

# Load your packages
library(tidyverse)
library(kableExtra)
library(dataRetrieval)
library(dplyr)
library(xts)
library(dygraphs)
library(lubridate)
library(gridExtra)
library(cowplot)
library(dataRetrieval)


# Set your ggplot theme
theme_set(theme_classic())
```


```{r, echo=FALSE}
# Loading in data

#reading in daily value data
bestsites.DNP <- read.csv("../Data/Raw/bestsites.DNP.csv")

#reading in water quality data
bestsites.wq <- read.csv("../Data/Raw/bestsites.WQ.csv")

#reading in high freq data
highfreqsiteinfo <- read.csv("../Data/Raw/highfreqsiteinfo.csv")


```


# Research Question and Rationale

<Paragraph detailing the rationale for your analysis. What is the significant application and/or interest in this topic? Connect to environmental topic(s)/challenge(s).>

<Paragraph detailing your research question(s) and goals. What do you want to find out? Include a sentence (or a few) on the dataset you are using to answer this question - just enough to give your reader an idea of where you are going with the analysis.>

\newpage

# Dataset Information

<Information on how the dataset for this analysis were collected, the data contained in the dataset, and any important pieces of information that are relevant to your analyses. This section should contain much of same information as the README file for the dataset but formatted in a way that is more narrative.>

The data we are analyzing comes from the United States Geological Survey (USGS) database called the National Water Information System interface, or NWIS. We pulled data from the interface using the R package `dataRetrieval`. Because we are interested in the lower Missouri River basin, we pulled sites from each HUC4 subbasin from 1020 to 1030 (see Figure below). We chose these subbasins because they had a variety of tributaries that all flowed into the Missouri River, and we wanted a variety of river sizes and lengths. We filtered these subbasin queries to only show us sites that had discharge, nitrogen, and phosphorus data. Once we found the sites with all of this data, we chose 2 sites from each HUC sub basin as our 22 "best sites". Our best sites had the overall best time period range for all of our "must have" variables.

Only seven sites within our HUC subbasin boundary contained any high frequency discharge and nitrogen data. Therefore, we also looked at these 7 sites in order to do analyses and answer our research question about flooding.

After doing initial data wrangling and analysis on our 22 "best sites", we decided to pare it down further and only do subsequent analyses on **10** sites. While we initially wanted to look at many sites that were varied in size and location, we determined that it was too many to look at and draw relevant conclusions from. 

We have three main datasets:

- The daily values dataset with our 22 "best sites"

- The water quality dataset with our 22 "best sites", with only six sites that had total coliform data.

- The high freqency dataset with 7 sites that contain both high freqency discharge and high frequency nitrogen data.

<Add a table that summarizes your data structure. This table can be made in markdown text or inserted as a `kable` function in an R chunk. If the latter, do not include the code used to generate your table.>

<C will do data table for water quality and daily values, R will do for high freq>


```{r, echo=FALSE, eval=TRUE}

#reading in daily value data
bestsites.DNP <- read.csv("../Data/Raw/bestsites.DNP.csv")

#reading in water quality data
bestsites.wq <- read.csv("../Data/Raw/bestsites.WQ.csv", colClasses=c("parm_cd"="character", 
                                                            "Date"="Date",
                                                            "site_no"="character"))

```


```{r, echo=FALSE, eval=TRUE, tbls="Summary of Daily Value Data at 22 sites in the Missouri River Basin", results="asis"}

#structure of daily value dataframe
dailyvalue.summary <- summary(bestsites.DNP)

#summary of data structure
kable(dailyvalue.summary, 
      caption = "Summary of Daily Value Data at 22 sites in the
      Missouri River Basin") %>% 
  kable_styling(latex_options = c("hold_position", "striped", 
                                  "scale_down")) %>% 
  kableExtra::landscape()

```

```{r, echo=FALSE, eval=TRUE, tbls="Summary of Water Quality Data at 22 sites in the Missouri River Basin", results="asis"}

#structure of water quality dataframe
waterquality.summary <- summary(bestsites.wq)

#summary of data structure
kable(waterquality.summary, 
      caption = "Summary of Water Quality Data in the
      Missouri River Basin") %>% 
  kable_styling(latex_options = c("hold_position", "striped", 
                                  "scale_down")) %>% 
  kableExtra::landscape() 

```

\newpage

# Exploratory Data Analysis and Wrangling

<Include R chunks for 5+ lines of summary code (display code and output), 3+ exploratory graphs (display graphs only), and any wrangling you do to your dataset(s).> 

<Include text sections to accompany these R chunks to explain the reasoning behind your workflow, and the rationale for your approach.>

#### Water Quality Data ####
    
There were 6 sites in the Missiour River Basin that had total coliform data in addition to total nitrogen, total phosphorus, pH, and discharge data. Out of the 6 sites, only *3* of the sites were chosen for water quality analysis because they had the most data for all of the parameters for water quality. The water quality data was wrangeled to include certain columns necessary for the analysis. The sites that were looked at in depth for water quality analysis are: 

    - 06810000
    - 06856600
    - 06934500

```{r}

#filtering water quality dataset to include only 3 sites
bestsites.wq.skinny <- bestsites.wq %>%
    select(Site = site_no,
              Date = Date,
              Parameter = parm_cd,
              Value = result_va,
              Discharge = X_00060_00003) %>%
    group_by(Date, Parameter, Site) %>%
    summarize(Value = mean(Value),
              Discharge = mean(Discharge)) %>%
    spread(key = Parameter, value = Value) %>% 
    rename(pH = '00400', total.coliform = '31501', 
           Discharge2 = '00060', total.nitrogen = '00600', 
           total.phosphorus = '00665') %>%
    mutate(Year = year(Date)) %>%
    select(-Discharge2) %>%     
    filter(Site == "06810000" | Site == "06856600" |
           Site == "06934500")
```

Graphs were made to look at total phosphorus, total nitrogen, pH, and total coliform over time. These figures were also faceted by site to see whether there were trends in specific sites. 

```{r tp.time, echo=FALSE, warning=FALSE, fig.cap="\\label{fig:tp.time}Total Phosphorus Over Time"}

#plot of TP with 3 sites that have total coliform, facet by site
TP.plot.2 <- ggplot(bestsites.wq.skinny, aes(x = Date, y = total.phosphorus)) +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_wrap(~Site) +
  xlim(as.Date(c("1969-01-01", "1980-01-01"))) +
  theme_bw() +
  labs(x = "Date", y = "Total Phosphorus (mg/L)")

#plot of TP over time with 3 sites that have total coliform
TP.plot <- ggplot(bestsites.wq.skinny, 
                       aes(x = Date, y = total.phosphorus)) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(x = "Date", y = "Total Phosphorus (mg/L)") +
  xlim(as.Date(c("1969-01-01", "2020-01-01"))) +
  theme(axis.title.x=element_blank())

#grid arrange for TP graphs
grid.arrange(TP.plot, TP.plot.2)
```

As seen by \autoref{fig:tp.time}, total phosphorus values have a slight positive trend. From \autoref{fig:tp.time}, site 06934500 has the most total phosphorus data.

```{r tn.time, echo=FALSE, warning=FALSE, fig.cap="\\label{fig:tn.time}Total Nitrogen Over Time" }
#plot of TN with 3 sites that have total coliform data
TN.plot.2 <- ggplot(bestsites.wq.skinny, aes(x = Date, y = total.nitrogen)) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(x = "Date", y = "Total Nitrogen (mg/L)") +
  xlim(as.Date(c("1969-01-01", "2020-01-01"))) +
  theme(axis.title.x=element_blank())

#TN over time facet by site
TN.plot.site <- ggplot(bestsites.wq.skinny, 
                       aes(x = Date, y = total.nitrogen)) +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_wrap(~Site) +
  labs(x = "Date", y = "Total Nitrogen (mg/L)") +
  xlim(as.Date(c("1969-01-01", "2020-01-01"))) +
  theme_bw()

#grid arrange for TN over time
grid.arrange(TN.plot.2, TN.plot.site)
```

From \autoref{fig:tn.time}, total nitrogen looks as though there is a slight positive trend from 1980 to 2019. Again, site 06934500 has the most total nitrogen data, as evidenced in \autoref{fig:tn.time}.

```{r ph, echo=FALSE, warning=FALSE, fig.cap="\\label{fig:ph}pH Over Time"}

#plot of pH with 3 sites that have total coliform
ph.plot.2 <- ggplot(bestsites.wq.skinny, aes(x = Date, y = pH)) +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_wrap(~Site) +
  xlim(as.Date(c("1960-01-01", "2020-01-01")))

#plot of pH in 3 sites with total coliform data over time
ph.plot <- ggplot(bestsites.wq.skinny, aes(x = Date, y = pH)) +
  geom_point() +
  geom_smooth(method = "lm") +
  xlim(as.Date(c("1960-01-01", "2020-01-01"))) +
  theme(axis.title.x=element_blank())

#grid arrange for pH plot
grid.arrange(ph.plot, ph.plot.2)
```

As seen in \autoref{fig:ph}, pH values range from below pH of 7 to above pH of 9 from 1970 - 2019. From \autoref{fig:ph}, site 06810000 has a positive increase in pH over time, whereas site 06934500 has a decreasing trend in pH over time.

```{r tc.time, echo=FALSE, warning=FALSE, fig.cap="\\label{fig:tc.time}Total Coliform Over Time"}
#plot of total coliform over time
TC.plot.time <- ggplot(bestsites.wq.skinny,
                  aes(x = Date, y = total.coliform)) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(x = "Date", y = "Total Coliform (cfu/100 ml)") +
  xlim(as.Date(c("1969-01-01"," 1975-12-31"))) +
  facet_wrap(~Site) +
  theme_set(theme_bw())

#plot of total coliform over time
tc.time <- ggplot(bestsites.wq.skinny, aes(x = Date, y = total.coliform)) +
  geom_point() + 
  geom_smooth(method = "lm") +
  xlim(as.Date(c("1969-01-01", "1975-01-01"))) +
  labs(x = "Date", y = "Total Coliform (cfu/100 ml)") +
  theme(axis.title.x=element_blank())

#grid arrange to put the plots on one figure
grid.arrange(tc.time, TC.plot.time, nrow = 2)
```

\autoref{fig:tc.time} shows the total coliform measurements in the 3 chosen sites over time. From \autoref{fig:tc.time}, it is evident that there is not much data on total coliform in the Missouri River Basin and monitoring for total coliform occured at these 3 sites from late 1960s through 1975.

```{r tc.dis, echo=FALSE, warning=FALSE, fig.cap="\\label{fig:tc.dis}Total Coliform over time and Discharge over time" }

#plot of total coliform over time
totalcoliform.time <- ggplot(bestsites.wq.skinny, aes(x = Date)) +
  geom_line(aes(y = Discharge, alpha = 0.5), color = "black") +
  geom_point(aes(y = total.coliform, alpha = 0.5), color = "red") +
  scale_y_continuous(sec.axis = sec_axis(~ . * 1.20, name = "Discharge (cfs)")) +
  xlim(as.Date(c("1969-01-01", "1980-01-01"))) +
  labs(x = "Date", y = "Total Coliform (cfu/100 ml)")
print(totalcoliform.time)

```

\autoref{fig:tc.dis} was created to determine whether high amounts of total coliform coincided with an increase in discharge. Because there were limited total coliform measurements taken, as evidenced in \autoref{fig:tc.time}, there is not a great conclusion from this data. However, \autoref{fig:tc.dis} shows a spike in discharge events between 1972 - 1974, which also happens to be a time when total coliform was sampled. \autoref{fig:tc.dis} also shows increases in total coliform between 1972 - 1975. 

```{r}
#high frequency data wrangling
highfreqsite2019 <- highfreqsiteinfo %>%
  filter(end_date > "2019-03-31"); head(highfreqsite2019)

highfreqsites.DN <- readNWISuv(site = c("06808500", "06817000", "06892350", "06934500"), 
                               parameterCd = c("00060", "99133"), 
                               # Discharge in cfs & Nitrate in mg/l NO3-N
                               startDate = "2019-01-01",
                               endDate = "2019-11-01") %>%
                               renameNWISColumns() %>%
                               rename(Nitrate_mgl = 6)

#individual sites
Hermann <- highfreqsites.DN %>%
           filter(site_no=="06934500")
Desoto <- highfreqsites.DN %>%
          filter(site_no=="06892350")
Clarinda <- highfreqsites.DN %>%
            filter(site_no=="06817000")
Randolph <- highfreqsites.DN %>%
            filter(site_no=="06808500")
```


### High Frequency Nitrogen and Discharge

There were 7 sites in our region of interest that had high freq N data, and only 4 sites had high freq N data during the floods of 2019. The sites looked at in depth are:

    - West Nishnabotna River in Randolph, IA
    - Nodaway River at Clarinda, IA
    - Kansas River in Desoto, KS
    - Missouri River at Hermann, MO

The Missouri River is the biggest river, with an average of 214693 cfs discharge rate during the year 2019, and the Nodaway River is the smallest river, with an average of 1185 cfs discharge rate for 2019.

In March of 2019, a [bomb cyclone](https://www.kansascity.com/news/state/missouri/article228237519.html) hit the midwest. Our initial research question, what effect did the March 2019 storm have on water quality, attempted to look into the behavior of nitrogen in the discharge of the rivers. Unfortunately, instantaneous Nitrogen values stopped recording during the peak of the storm events in March, so it was hard to create hysteresis plots that exhibited the type of storm and its effects on nitrogen concentration. 

Even though Nitrogen concentrations were not recorded in March, they were recorded in other times of the year. 2019 was a wet year and many large storm events occurred. 

```{r randolphs, echo=FALSE}
#Randolph storm
RandolphStorm <- Randolph %>%
  filter(dateTime > "2019-06-24" & dateTime < "2019-07-08") 


RandolphStorm.plot <- ggplot(RandolphStorm, aes(x = Flow_Inst, y = Nitrate_mgl, color = dateTime)) +
  geom_point() +
  labs(x="Discharge (cfs)", y= "Nitrogen mg/l)", color="Date", 
       title="West Nishnabotna River in Randolph, IA")

#semi-clockwise motion, negative slope, so diluting
```

```{r desotos, fig.cap="\\label{fig:desotos} Hysteresis plots", echo=FALSE}
#desoto storm

DesotoStorm <- Desoto %>%
  filter(dateTime > "2019-02-22" & dateTime < "2019-02-28") 


DesotoStorm.plot <- ggplot(DesotoStorm, aes(x = Flow_Inst, y = Nitrate_mgl, color = dateTime)) +
  geom_point() +
  labs(x="Discharge (cfs)", y= "Nitrogen mg/l)", color="Date", 
       title="Kansas River in Desoto, KS")


plot_grid(RandolphStorm.plot, DesotoStorm.plot, ncol=1)
#very loose counter clockwise motion - loose positive slope for flushing storm
```

The \autoref{fig:desotos} shows Hysteresis plots for two storm events in the Missouri River Basin. The storm event on the West Nishnabotna River exhibits an oddly-shaped plot that has a negative slope, indicating it is a diluting storm. The Kansas River experienced a storm in late February that has a counter-clockwise motion and a positive slope, indicating a flushing storm. These two plots illustrate that two rivers near each other can have very different behaviors.

\newpage

# Analysis
<Include R chunks for 3+ statistical tests (display code and output) and 3+ final visualization graphs (display graphs only).>

<Include text sections to accompany these R chunks to explain the reasoning behind your workflow, rationale for your approach, and the justification of meeting or failing to meet assumptions of tests.>


\newpage

# Summary and Conclusions
<Summarize your major findings from your analyses. What conclusions do you draw from your findings? Make sure to apply this to a broader application for the research question you have answered.>


## Example for autoreferencing

As seen by \autoref{fig:foo}, Absorbance values are not normally distributed. This is expected, as we are dealing with ecological data.

```{r foo, echo=FALSE, warning=FALSE, fig.cap="\\label{fig:foo}Absorbance frequency"}
ggplot(cars) +
  geom_point(aes(x=speed, y= dist)) +
  labs(x= "Frequency", y="Absorbance value")
```
