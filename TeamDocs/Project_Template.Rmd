---
output: 
  pdf_document:
    keep_tex: yes
    fig_caption: yes
    number_sections: yes
geometry: margin=2.54cm
title: Examining the Hydrologic Properties of the Missouri River Basin
subtitle: https://github.com/cwatson1013/Hydrologic_Data_Analysis_Final_Proj
author: Rachel Bash, Keqi He, Caroline Watson, and Haoyu Zhang
abstract: "The Missouri River provides critical water resources that drives the region's agriculture, industry, and ecosystems. This is a region that experiences surface water variability, characterized by damaging floods and severe droughts, greatly impacting the agricultural production of the area. It is reported that a serious flood disaster occurred in the lower Missouri River in the spring of 2019 and the Missouri River experienced severe drought in 2012-2013. This project highlights the changes in stream flow and water quality over time, and identifies key characteristics of the river. Twenty two sites across the lower Missouri River Basin were examined in order to get a fuller picture of the Missouri River and its tributaries over time. By analyzing the trend of the Missouri River discharge, we can predict future changes in the Missouri River flow to provide a reference for water resources management. In addition, we focus on the stream flow and water quality of Missouri River during March to July, 2019 to see how discharge influence the water quality and what can be done to keep the water in the Missouri River in good quality."
fontsize: 12pt
mainfont: Times New Roman
editor_options: 
  chunk_output_type: console
---

<Information in these brackets are used for annotating the RMarkdown file. They will not appear in the final version of the PDF document>

\newpage
\tableofcontents 
\newpage
\listoftables 
\newpage
\listoffigures 
\newpage

<Setup the global options for the R chunks in your document>

<Note: set up autoreferencing for figures and tables in your document>

```{r setup, include=FALSE}
# Set your working directory
getwd()

# Load your packages
library(tidyverse)
library(kableExtra)

# Set your ggplot theme
theme_set(theme_classic())
```


# Research Question and Rationale

<Paragraph detailing the rationale for your analysis. What is the significant application and/or interest in this topic? Connect to environmental topic(s)/challenge(s).>

<Paragraph detailing your research question(s) and goals. What do you want to find out? Include a sentence (or a few) on the dataset you are using to answer this question - just enough to give your reader an idea of where you are going with the analysis.>

\newpage

# Dataset Information

<Information on how the dataset for this analysis were collected, the data contained in the dataset, and any important pieces of information that are relevant to your analyses. This section should contain much of same information as the README file for the dataset but formatted in a way that is more narrative.>

The data we are analyzing comes from the United States Geological Survey (USGS) database called the National Water Information System interface, or NWIS. We pulled data from the interface using the R package `dataRetrieval`. Because we are interested in the lower Missouri River basin, we pulled sites from each HUC4 subbasin from 1020 to 1030 (see Figure below). We chose these subbasins because they had a variety of tributaries that all flowed into the Missouri River, and we wanted a variety of river sizes and lengths. We filtered these subbasin queries to only show us sites that had discharge, nitrogen, and phosphorus data. Once we found the sites with all of this data, we chose 2 sites from each HUC sub basin as our 22 "best sites". Our best sites had the overall best time period range for all of our "must have" variables.

Only seven sites within our HUC subbasin boundary contained any high frequency discharge and nitrogen data. Therefore, we also looked at these 7 sites in order to do analyses and answer our research question about flooding.

After doing initial data wrangling and analysis on our 22 "best sites", we decided to pare it down further and only do subsequent analyses on **10** sites. While we initially wanted to look at many sites that were varied in size and location, we determined that it was too many to look at and draw relevant conclusions from. 

We have three main datasets:

    1. The daily values dataset with our 22 "best sites"
    2. The water quality dataset with our 22 "best sites", with only six sites that had total coliform data.
    3. The high freqency dataset with 7 sites that contain both high freqency discharge and high frequency nitrogen data.

<Add a table that summarizes your data structure. This table can be made in markdown text or inserted as a `kable` function in an R chunk. If the latter, do not include the code used to generate your table.>

<C will do data table for water quality and daily values, R will do for high freq>

```{r, echo=FALSE, eval=TRUE}
#reading in daily value data
bestsites.DNP <- read.csv("../Data/Raw/bestsites.DNP.csv")

#reading in water quality data
bestsites.wq <- read.csv("../Data/Raw/bestsites.WQ.csv")
```

```{r, echo=FALSE, eval=TRUE, tbls="Summary of Daily Value Data at 22 sites in the Missouri River Basin", results="asis"}

#structure of daily value dataframe
dailyvalue.summary <- summary(bestsites.DNP)

#summary of data structure
kable(dailyvalue.summary, 
      caption = "Summary of Daily Value Data at 22 sites in the
      Missouri River Basin") %>% 
  kable_styling(latex_options = c("hold_position", "striped", 
                                  "scale_down")) %>% 
  kableExtra::landscape()

```

```{r, echo=FALSE, eval=TRUE, tbls="Summary of Water Quality Data at 22 sites in the Missouri River Basin", results="asis"}

#structure of water quality dataframe
waterquality.summary <- summary(bestsites.wq)

#summary of data structure
kable(waterquality.summary, 
      caption = "Summary of Water Quality Data in the
      Missouri River Basin") %>% 
  kable_styling(latex_options = c("hold_position", "striped", 
                                  "scale_down")) %>% 
  kableExtra::landscape() 

```

\newpage

# Exploratory Data Analysis and Wrangling

<Include R chunks for 5+ lines of summary code (display code and output), 3+ exploratory graphs (display graphs only), and any wrangling you do to your dataset(s).> 

<Include text sections to accompany these R chunks to explain the reasoning behind your workflow, and the rationale for your approach.>


\newpage

# Analysis
<Include R chunks for 3+ statistical tests (display code and output) and 3+ final visualization graphs (display graphs only).>

<Include text sections to accompany these R chunks to explain the reasoning behind your workflow, rationale for your approach, and the justification of meeting or failing to meet assumptions of tests.>


\newpage

# Summary and Conclusions
<Summarize your major findings from your analyses. What conclusions do you draw from your findings? Make sure to apply this to a broader application for the research question you have answered.>


## Example for autoreferencing

As seen by \autoref{fig:foo}, Absorbance values are not normally distributed. This is expected, as we are dealing with ecological data.

```{r foo, echo=FALSE, warning=FALSE, fig.cap="\\label{fig:foo}Absorbance frequency"}
ggplot(cars) +
  geom_point(aes(x=speed, y= dist)) +
  labs(x= "Frequency", y="Absorbance value")
```
